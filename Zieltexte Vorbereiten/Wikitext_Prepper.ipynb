{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia API Scrapper\n",
    "\n",
    "In dieser Sektion greifen wir auf Wikipedia via die wikipediaapi Library zu. Dies ist ein bekannter Ansatz, um Inforamtionen von Wikipedia zu bekommen. Unsere Funktion greift auf das jeweilige Topic zu und schliesst alle sub-pages ein. Damit die Textlänge nicht ausufert, nimmt der Scrapper jeweils nur den ersten Abschnitt, also das Abstract, eines Themas und setzt dieses mit den anderen zusammen. So ergibt sich ein breiter Text mit vielen Subthemen des ausgewählten Themas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requiremend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\daveb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install wikipedia-api\n",
    "import wikipediaapi\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"..\")\n",
    "from nlp_functions import (classifier, remove_colons, remove_digits, remove_n,\n",
    "                           remove_redundant_whitespaces,\n",
    "                           remove_strange_characters, remove_stripes,\n",
    "                           text_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define language and page\n",
    "wiki = wikipediaapi.Wikipedia('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get members for a category together with a short description\n",
    "def members_collector_summary(category):\n",
    "      mdict = {}\n",
    "      categorymembers = category.categorymembers\n",
    "      for c in categorymembers.values():\n",
    "        if c.ns == 0:                                                            # Exclude categories within the category\n",
    "          mdict[c.title] = c.summary\n",
    "      return mdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get members for a category together with a short description\n",
    "def members_collector_fulltext(category):\n",
    "      mdict = {}\n",
    "      categorymembers = category.categorymembers\n",
    "      for c in categorymembers.values():\n",
    "        if c.ns == 0:                                                            # Exclude categories within the category\n",
    "          mdict[c.title] = c.text\n",
    "      return mdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_to_text_fulltext(topic):\n",
    "    import pandas as pd\n",
    "    import wikipediaapi\n",
    "\n",
    "    # Define language and page\n",
    "    wiki = wikipediaapi.Wikipedia('en')\n",
    "    # Setting the sustainability Category\n",
    "    wiki_topic = wiki.page(f\"Category:{topic}\")\n",
    "    topic_dict = members_collector_fulltext(wiki_topic) \n",
    "\n",
    "    # Create the dataframe for sustainability\n",
    "    df_topic = pd.DataFrame([topic_dict.keys(), topic_dict.values()]).T\n",
    "    df_topic.columns = ['Article', 'Description']\n",
    "    df_topic\n",
    "    topic_text = []\n",
    "    topic_list = df_topic[\"Description\"][:]\n",
    "    for i in topic_list:\n",
    "            topic_text.append(i)\n",
    "    return topic_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_to_text_summary(topic):\n",
    "    import pandas as pd\n",
    "    import wikipediaapi\n",
    "\n",
    "    # Define language and page\n",
    "    wiki = wikipediaapi.Wikipedia('en')\n",
    "    # Setting the sustainability Category\n",
    "    wiki_topic = wiki.page(f\"Category:{topic}\")\n",
    "    topic_dict = members_collector_summary(wiki_topic)\n",
    "\n",
    "    # Create the dataframe for sustainability\n",
    "    df_topic = pd.DataFrame([topic_dict.keys(), topic_dict.values()]).T\n",
    "    df_topic.columns = ['Article', 'Description']\n",
    "    df_topic\n",
    "    topic_text = []\n",
    "    topic_list = df_topic[\"Description\"][:]\n",
    "    for i in topic_list:\n",
    "            topic_text.append(i)\n",
    "    return topic_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_candidate = ['sustainability', 'human rights', 'fraud', 'social issues', 'labour law'] # no data with employee affairs\n",
    "label_fulltext_list = []\n",
    "wiki_dict = {\"Label\": [], \"Text\": []}\n",
    "\n",
    "for i in label_candidate:\n",
    "    label_fulltext_list.append(scrape_to_text_fulltext(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_candidate = ['sustainability', 'human rights', 'fraud', 'social issues', 'labour law'] # no data with employee affairs\n",
    "label_summary_list = []\n",
    "wiki_dict_fulltext = {\"Label\": [], \"Text\": []}\n",
    "\n",
    "for i in label_candidate:\n",
    "    label_summary_list.append(scrape_to_text_summary(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_dict_fulltext = dict(zip(label_candidate, label_fulltext_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_dict_summary = dict(zip(label_candidate, label_summary_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in wiki_dict_fulltext.items():\n",
    "    wiki_dict_fulltext[k] = \" \".join(v)\n",
    "\n",
    "    wiki_dict_fulltext[k] = remove_strange_characters(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'str'>\n",
      "<class 'str'> <class 'str'>\n",
      "<class 'str'> <class 'str'>\n",
      "<class 'str'> <class 'str'>\n",
      "<class 'str'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for k, v in wiki_dict_fulltext.items():\n",
    "    wiki_dict_fulltext[k] = remove_n(v)\n",
    "\n",
    "    wiki_dict_fulltext[k] = remove_colons(v)\n",
    "\n",
    "    wiki_dict_fulltext[k] = v.replace(r\" .\",\".\")\n",
    "    wiki_dict_fulltext[k] = v.replace(r\"..\",\".\")\n",
    "    wiki_dict_fulltext[k] = v.replace(r\"...\",\".\")\n",
    "\n",
    "    wiki_dict_fulltext[k] = remove_stripes(v)\n",
    "\n",
    "    wiki_dict_fulltext[k] = remove_redundant_whitespaces(v)\n",
    "    wiki_dict_fulltext[k] = remove_digits(v)\n",
    "    print(type(k), type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in wiki_dict_summary.items():\n",
    "    wiki_dict_summary[k] = \" \".join(v)\n",
    "\n",
    "    wiki_dict_summary[k] = remove_strange_characters(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> <class 'str'>\n",
      "<class 'str'> <class 'str'>\n",
      "<class 'str'> <class 'str'>\n",
      "<class 'str'> <class 'str'>\n",
      "<class 'str'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for k, v in wiki_dict_summary.items():\n",
    "    wiki_dict_summary[k] = remove_n(v)\n",
    "\n",
    "    wiki_dict_summary[k] = remove_colons(v)\n",
    "\n",
    "    wiki_dict_summary[k] = v.replace(r\" .\",\".\")\n",
    "    wiki_dict_summary[k] = v.replace(r\"..\",\".\")\n",
    "    wiki_dict_summary[k] = v.replace(r\"...\",\".\")\n",
    "\n",
    "    wiki_dict_summary[k] = remove_stripes(v)\n",
    "\n",
    "    wiki_dict_summary[k] = remove_redundant_whitespaces(v)\n",
    "    wiki_dict_summary[k] = remove_digits(v)\n",
    "    print(type(k), type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(wiki_dict_fulltext.items()),columns = ['Label','Text']) \n",
    "df.to_csv(r\"..\\Data\\Resultate\\Testfolder\\wiki_artikel_fulltext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(wiki_dict_summary.items()),columns = ['Label','Text']) \n",
    "df.to_csv(r\"..\\Data\\Resultate\\Testfolder\\wiki_artikel_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcf02d00a6b3e7f0f947d643ae902f18bdd390f284f55fc20de5769d141d0127"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
