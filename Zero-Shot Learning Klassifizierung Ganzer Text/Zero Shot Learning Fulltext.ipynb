{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\daveb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\daveb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import io\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import contractions\n",
    "import gensim.downloader as api\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import spacy\n",
    "import torch\n",
    "import torchvision\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import TreebankWordTokenizer, sent_tokenize, word_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from pdfminer3.converter import PDFPageAggregator, TextConverter\n",
    "from pdfminer3.layout import LAParams, LTTextBox\n",
    "from pdfminer3.pdfinterp import PDFPageInterpreter, PDFResourceManager\n",
    "from pdfminer3.pdfpage import PDFPage\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from spacy.lang.en import English\n",
    "from transformers import pipeline\n",
    "\n",
    "sys.path.append(r\"..\")\n",
    "\n",
    "from nlp_functions import (classifier, remove_colons, remove_digits, remove_n,\n",
    "                           remove_redundant_whitespaces,\n",
    "                           remove_strange_characters, remove_stripes,\n",
    "                           text_loader)\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# import io\n",
    "# import itertools\n",
    "# import os\n",
    "# import re\n",
    "# import string\n",
    "# import unicodedata\n",
    "\n",
    "# import contractions\n",
    "\n",
    "# import pandas as pd\n",
    "# # import torch\n",
    "# # import torchvision\n",
    "# # from gensim.models import Word2Vec\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# from nltk.tokenize import TreebankWordTokenizer, sent_tokenize, word_tokenize\n",
    "# from nltk.tokenize.toktok import ToktokTokenizer\n",
    "# # from pdfminer3.converter import PDFPageAggregator, TextConverter\n",
    "# # from pdfminer3.layout import LAParams, LTTextBox\n",
    "# # from pdfminer3.pdfinterp import PDFPageInterpreter, PDFResourceManager\n",
    "# # from pdfminer3.pdfpage import PDFPage\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from spacy.lang.en import English\n",
    "# from transformers import pipeline\n",
    "\n",
    "# sys.path.append(r\"..\")\n",
    "\n",
    "# from nlp_functions import (classifier, remove_colons, remove_digits, remove_n,\n",
    "#                            remove_redundant_whitespaces,\n",
    "#                            remove_strange_characters, remove_stripes,\n",
    "#                            text_loader)\n",
    "\n",
    "# # nltk.download('punkt')\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_loader(company_name): \n",
    "    \"\"\"Nimmt PDF-File Namen entgegen. Gibt Text als String, PDF-Namen, Pfad inkl. PDF-Namen sowie Pfad ohne PDF-Namen zurück\"\"\"\n",
    "    company_name = company_name[:-4]\n",
    "    source = r'..\\Data\\Nachhaltigkeitsberichte\\Alle'\n",
    "    path = rf\"{source}\\{company_name}.pdf\"\n",
    "\n",
    "    text = text_loader(path)   \n",
    "\n",
    "    return text, company_name, path, source \n",
    "\n",
    "def topic_modeler(text):\n",
    "    \"\"\"Errechnet die Klassifizierungs-Wahrscheinlichkeiten für den Text für die vorgegebenen Label aus\"\"\"\n",
    "\n",
    "    classifier_pipeline = pipeline(\n",
    "        \"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "    input_sequence = text\n",
    "    label_candidate = ['sustainability', 'human rights',\n",
    "                       'fraud', 'social issues', 'labour law']\n",
    "    x = classifier_pipeline(input_sequence, label_candidate)\n",
    "    result_label = x[\"labels\"]\n",
    "    result_score = x[\"scores\"]\n",
    "    tuple_for_df = list(zip(result_label, result_score))\n",
    "    df_topic_modeling_score = pd.DataFrame(\n",
    "        tuple_for_df, columns=[\"Label\", \"Score\"])\n",
    "    return df_topic_modeling_score\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    # mapping = str.maketrans('', '', string.digits)\n",
    "    # text = text.translate(mapping)\n",
    "\n",
    "    text = remove_strange_characters(text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    text = remove_n(text)\n",
    "\n",
    "    text = remove_colons(text)\n",
    "\n",
    "    text = text.replace(r\" .\", \".\")\n",
    "    text = text.replace(r\"..\", \".\")\n",
    "    text = text.replace(r\"...\", \".\")\n",
    "\n",
    "    text = remove_stripes(text)\n",
    "\n",
    "    text = remove_redundant_whitespaces(text)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TI-IDF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\daveb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\daveb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(text):\n",
    "    \"\"\"Wendet verschiedene Standard-Preprocessings auf den Text an.\"\"\"\n",
    "\n",
    "\n",
    "    text = remove_strange_characters(text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "\n",
    "    text = remove_n(text)\n",
    "\n",
    "    text = remove_colons(text)\n",
    "\n",
    "    text = text.replace(r\" .\",\".\")\n",
    "    text = text.replace(r\"..\",\".\")\n",
    "    text = text.replace(r\"...\",\".\")\n",
    "\n",
    "    text = remove_stripes(text)\n",
    "\n",
    "    text = remove_redundant_whitespaces(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    \"\"\"Formt Worte im Text in ihre Lemma um\"\"\"\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = word_tokenize(text)\n",
    "\n",
    "    lemma_list = []\n",
    "\n",
    "    for word in text:\n",
    "        lemma_word = lemmatizer.lemmatize(word)\n",
    "        lemma_list.append(lemma_word)\n",
    "\n",
    "    lemma_text = ' '.join(lemma_list)\n",
    "\n",
    "\n",
    "    return lemma_text\n",
    "\n",
    "\n",
    "\n",
    "def remove_small_tokens(prep_text):\n",
    "    \"\"\"Entfernt Tokens, welche kleiner als Vier sind.\"\"\"\n",
    "    prep_text_before = prep_text\n",
    "    # print(f\"Text before cleaning:  {len(prep_text_before)}\")\n",
    "    # print(type(prep_text_before))\n",
    "    # prep_text_before = [prep_text_before]\n",
    "    prep_text_before = word_tokenize(prep_text_before)\n",
    "    # print(prep_text_before)\n",
    "\n",
    "    for word in prep_text_before:\n",
    "        if len(word) <= 3:\n",
    "            prep_text_before.remove(word)\n",
    "    # print(f\"Text after cleaning:  {len(prep_text_before)}\")\n",
    "    prep_text_list = ' '.join(prep_text_before)\n",
    "    # print(type(prep_text_list))\n",
    "\n",
    "\n",
    "    return prep_text_list\n",
    "\n",
    "# BOW\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    \"\"\"Errechnet die N-Meistgenannten Worte\"\"\"\n",
    "    corpus=[corpus]\n",
    "\n",
    "    vec = CountVectorizer(stop_words = 'english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    top_n_words_df = pd.DataFrame(words_freq, columns =['Word', 'Count'])\n",
    "\n",
    "    return top_n_words_df.loc[:(n-1)]\n",
    "\n",
    "\n",
    "def get_tf_idf(text, n=None):\n",
    "    \"\"\"Errechnet den TF-IDF Score für die N-höchsten Scores\"\"\"\n",
    "    text = re.findall(r'(?:\\d[.]|[^.])*(?:[.]|$)', text)\n",
    "    tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
    "    tfIdf = tfIdfVectorizer.fit_transform(text)\n",
    "    df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "    df = df.sort_values('TF-IDF', ascending=False)\n",
    "    return (df[:(n)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4f303cec-a12d-480b-accb-7b56f706f60e_axa-ri2020-en-accessible.pdf',\n",
       " '4f391131-ad12-ab53-7265-5e6c88840627.pdf',\n",
       " '5ZmOsI2P3oe0plCvOThrCySgcDcKCXqj.pdf',\n",
       " '9clin.pdf',\n",
       " '10_BCGB20_SustainabilityReport_E_Web.pdf',\n",
       " '668a8a26-d924-21aa-cd75-c12e5296ff2b.pdf',\n",
       " '1212.pdf',\n",
       " '1313.pdf',\n",
       " '2012-CSR-report.pdf',\n",
       " '2017-Glencore-Sustainability-Report-FINAL-.pdf',\n",
       " '2019_Straumann_sustainability_report.pdf',\n",
       " '2019-sustainability-report-doc-en.pdf',\n",
       " '2020_dnf_-_eng_0.pdf',\n",
       " '2020_Sustainability_Report.pdf',\n",
       " '2020_valora_geschaeftsbericht_de.pdf',\n",
       " '2020-Annual-Report-7u42lsu22.pdf',\n",
       " '2020-responsibility-highlights-report.pdf',\n",
       " '2020-sustainability-report-doc-en.pdf',\n",
       " '2021-03-22_JuliusBaer_CorporateSustainabilityReport2020_EN.pdf',\n",
       " '210928_UBP20Sustainability20Report.pdf',\n",
       " '2641133_DOWNLOAD.pdf',\n",
       " '20200625_man-es_pr_cr-report_2020_en.pdf',\n",
       " 'abb-group-sustainability-performance-report-2015.pdf',\n",
       " 'Allianz_Group_Sustainability_Report_2020-web (1).pdf',\n",
       " 'Allianz_Group_Sustainability_Report_2020-web.pdf',\n",
       " 'Allreal_Sustainability_Report_EN_2020.pdf',\n",
       " 'AMAG_Geschaeftsbericht_2021_Magazin_Englisch.pdf',\n",
       " 'Ancient Rome Did Not Fall_ Why Real Story is Even Scarier for America and How It Connects to Billionaires _ by Barry Gander _ Nov, 2022 _ Medium.pdf',\n",
       " 'annual-and-sustainability-report-2020.pdf',\n",
       " 'annual-report-2020.pdf',\n",
       " 'apollo-esg-report-v-12.pdf',\n",
       " 'ar21e.pdf',\n",
       " 'avaloq-csr-2020-report.pdf',\n",
       " 'Avoid the Reorg from Hell with Six Key Principles _ by Saumil Mehta _ Nov, 2022 _ Medium.pdf',\n",
       " 'Bucher Sustainability report 2020.pdf',\n",
       " 'Buckingham Palace race row raises awkward questions - BBC News.pdf',\n",
       " 'c05179523.pdf',\n",
       " 'cargill-aqua-nutrition-sustainability-report.pdf',\n",
       " 'celgene-responsibility.pdf',\n",
       " 'ClariantIntegratedReport2020EN.pdf',\n",
       " 'coca-cola-business-environmental-social-governance-report-2020.pdf',\n",
       " 'COOP_NHB_2011_e_low.pdf',\n",
       " 'Corporate_Sustainability_Report_2019_Web.pdf',\n",
       " 'Coutts20Sustainability20Report.pdf',\n",
       " 'CPN_Fortschrittsbericht_EN_v02.pdf',\n",
       " 'csg-sr-2020-en.pdf',\n",
       " 'CSR_Report_2019_en.pdf',\n",
       " 'CSR_Report_2020.pdf',\n",
       " 'CSR20leaflet_A4.pdf',\n",
       " 'decarbonisation-role-of-TSOs-en.pdf',\n",
       " 'DECATHLON-Nachhaltigkeitsbericht-2019-engl.-2.pdf',\n",
       " 'Dufry20Corporate20Brochure202021.pdf',\n",
       " 'EFGAM20engagement20policy202021_final.pdf',\n",
       " 'EN_Post_Nachhaltigkeitsbericht_2019.pdf',\n",
       " 'Environmental-Social-and-Governance-TCFD-Report.pdf',\n",
       " 'Feintool_Sustainability_Report_2019_EN_4-8-20.pdf',\n",
       " 'Firmenich-Sustainability-Report-2020.pdf',\n",
       " 'Fussball-WM_ Auch Gastarbeiter sind echte Fussballfans.pdf',\n",
       " 'FY20_Corporate_Sustainability_EN.pdf',\n",
       " 'ge2020_sustainability_report.pdf',\n",
       " 'GF_NHB19_Sustainability-at-GF.pdf',\n",
       " 'girsberger-sustainability-report2020.pdf',\n",
       " 'giv-2019-sustainability-gri-index.pdf',\n",
       " 'GKB_2020_Geschaeftsbericht-DE.pdf',\n",
       " 'Glencore_SR202020_Interactive_Final_20optimised.pdf',\n",
       " 'glkb_2020_geschaeftsbericht-kurzform_glarner-kantonalbank-glarus-glarnerland.pdf.pdf',\n",
       " 'glo-annual-report-2020-sustainability-report.pdf',\n",
       " 'google-2021-environmental-report.pdf',\n",
       " 'HM-Group-Sustainability-Performance-Report-2020.pdf',\n",
       " 'HOCHDORF_Annual-Report_2020.pdf',\n",
       " 'How the Collapse of Sam Bankman-Fried’s Crypto Empire Has Disrupted A.I. - The New York Times.pdf',\n",
       " 'HSE20Policy.pdf',\n",
       " 'IIC-Sustainability-Report-2020.pdf',\n",
       " 'ikea_sustainability_report_fy20.pdf',\n",
       " 'Implenia_nachhaltigkeit_Pdf_Version_DE.pdf',\n",
       " 'index.pdf',\n",
       " 'IWC_Sustainability_Targets_16.pdf',\n",
       " 'Jahresbericht202020_DE_web.pdf',\n",
       " 'MB_GB2018_EN_Sustainability.pdf',\n",
       " 'mediclinic-international-sustainable-development-overview-2021.pdf',\n",
       " 'Nachhaltigkeitsbericht-2020-DE.pdf',\n",
       " 'nestle-tackling-child-labor-report-2019-en.pdf',\n",
       " 'novartis-environmental-sustainability-occupational-heatlth-safety-data-supplement-2020.pdf',\n",
       " 'Opinion _ Germany’s Coach Is Out of His Depth, and So Is Its Chancellor - The New York Times.pdf',\n",
       " 'ORIOR20Sustainability20Report202020.pdf',\n",
       " 'pmi-sustainability-report-2018-highlights.pdf',\n",
       " 'ProgressReport2019.pdf',\n",
       " 'PSP_GB_2020_en_Nachhaltigkeit.pdf',\n",
       " 'responsibility-report-2020-en.pdf',\n",
       " 'RWyG1q.pdf',\n",
       " 'sap-2019-integrated-report.pdf',\n",
       " 'schindler-corporate-responsibility-report-2020.pdf',\n",
       " 'SD-Payments-to-governments-report-2019.pdf',\n",
       " 'sgs-2020-corporate-sustainability-report.pdf',\n",
       " 'six-corporate-responsibility-report-2020-en.pdf',\n",
       " 'social-impact-report-2020.pdf',\n",
       " 'Sulzer_Geschaftsbericht_2020_de.pdf',\n",
       " 'Sunrise_Annual_Report_2019.pdf',\n",
       " 'sustainability_report_2020_web3_0.pdf',\n",
       " 'sustainability_report_en_2019.pdf',\n",
       " 'Sustainability20Key20Figures.pdf.coredownload.pdf',\n",
       " 'SustainabilityReport_EN2020.pdf',\n",
       " 'sustainability-report-2019_all-in-one-2.pdf',\n",
       " 'sustainability-report-2020.pdf',\n",
       " 'sustainability-report-2020-2.pdf',\n",
       " 'sustainability-report-2020-aw-09-spread.pdf',\n",
       " 'sustainability-report-2021.pdf',\n",
       " 'sustainability-report-fy21-aw-spreads.pdf',\n",
       " 'Swarovski_Sustainability_Report_2021.pdf',\n",
       " 'swatchgroup_sustainability_report_2020 (1).pdf',\n",
       " 'swatchgroup_sustainability_report_2020.pdf',\n",
       " 'SwissLife_SustainabilityReport_2019 (1).pdf',\n",
       " 'SwissLife_SustainabilityReport_2019.pdf',\n",
       " 'Syngenta-ESG-Report-2020.pdf',\n",
       " 'takeda2020sustainabilityreport_en.pdf',\n",
       " 'ubs-sustainability-report-2020.pdf',\n",
       " 'umfrage_digitaler_test_de.pdf',\n",
       " 'Unnamedattachment.pdf',\n",
       " 'Vacheron-Constantin-Due-Diligence-Report.pdf',\n",
       " 'Volg_Geschaeftsbericht-2020.pdf',\n",
       " 'VPBank_Sustainability_report_en.pdf',\n",
       " 'wuerth_nachhaltigkeitsbericht_2019_1.pdf',\n",
       " 'Zegna-responsibility.pdf',\n",
       " '5df03cc1-f2ec-65ed-9c3d-da3c343395a5.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_companies = os.listdir(r\"..\\Data\\Nachhaltigkeitsberichte\\Alle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We process now 4f303cec-a12d-480b-accb-7b56f706f60e_axa-ri2020-en-accessible.pdf\n",
      "axa_health_customer SAFED\n",
      "We process now 4f391131-ad12-ab53-7265-5e6c88840627.pdf\n",
      "global_safety_training SAFED\n",
      "We process now 5ZmOsI2P3oe0plCvOThrCySgcDcKCXqj.pdf\n",
      "die_lindt_sprüngli SAFED\n",
      "We process now 9clin.pdf\n",
      "chemical_mitsubishi_employee SAFED\n",
      "We process now 10_BCGB20_SustainabilityReport_E_Web.pdf\n",
      "cid_burckhardt_compression SAFED\n",
      "We process now 668a8a26-d924-21aa-cd75-c12e5296ff2b.pdf\n",
      "bcge_financial_board SAFED\n",
      "We process now 1212.pdf\n",
      "bell_food_group SAFED\n",
      "We process now 1313.pdf\n",
      "bell_food_group SAFED\n",
      "We process now 2012-CSR-report.pdf\n",
      "dsv_employee_target SAFED\n",
      "We process now 2017-Glencore-Sustainability-Report-FINAL-.pdf\n",
      "community_glencore_report SAFED\n",
      "We process now 2019_Straumann_sustainability_report.pdf\n",
      "dental_report_production SAFED\n",
      "We process now 2019-sustainability-report-doc-en.pdf\n",
      "swiss_risk_sustainability SAFED\n",
      "We process now 2020_dnf_-_eng_0.pdf\n",
      "group_autogrill_management SAFED\n",
      "We process now 2020_Sustainability_Report.pdf\n",
      "braun_employee_management SAFED\n",
      "We process now 2020_valora_geschaeftsbericht_de.pdf\n",
      "valora_financial_group SAFED\n",
      "We process now 2020-Annual-Report-7u42lsu22.pdf\n",
      "temenos_financial_year SAFED\n",
      "We process now 2020-responsibility-highlights-report.pdf\n",
      "vifor_pharma_patient SAFED\n",
      "We process now 2020-sustainability-report-doc-en.pdf\n",
      "swiss_sustainability_risk SAFED\n",
      "We process now 2021-03-22_JuliusBaer_CorporateSustainabilityReport2020_EN.pdf\n",
      "sustainability_risk_report SAFED\n",
      "We process now 210928_UBP20Sustainability20Report.pdf\n",
      "ubp_sustainability_investment SAFED\n",
      "We process now 2641133_DOWNLOAD.pdf\n",
      "football_uefa_social SAFED\n",
      "We process now 20200625_man-es_pr_cr-report_2020_en.pdf\n",
      "energy_solutions_company SAFED\n",
      "We process now abb-group-sustainability-performance-report-2015.pdf\n",
      "abb_sustainability_performance SAFED\n",
      "We process now Allianz_Group_Sustainability_Report_2020-web (1).pdf\n",
      "sustainability_allianz_risk SAFED\n",
      "We process now Allianz_Group_Sustainability_Report_2020-web.pdf\n",
      "sustainability_allianz_risk SAFED\n",
      "We process now Allreal_Sustainability_Report_EN_2020.pdf\n",
      "allreal_report_employee SAFED\n",
      "We process now AMAG_Geschaeftsbericht_2021_Magazin_Englisch.pdf\n",
      "amag_aluminium_austria SAFED\n",
      "We process now Ancient Rome Did Not Fall_ Why Real Story is Even Scarier for America and How It Connects to Billionaires _ by Barry Gander _ Nov, 2022 _ Medium.pdf\n",
      "Ancient Rome Did Not Fall_ Why Real Story is Even Scarier for America and How It Connects to Billionaires _ by Barry Gander _ Nov, 2022 _ Medium.pdf didn't work\n",
      "We process now annual-and-sustainability-report-2020.pdf\n",
      "volvo_group_financial SAFED\n",
      "We process now annual-report-2020.pdf\n"
     ]
    }
   ],
   "source": [
    "for company in list_of_companies:\n",
    "    ## BOW / TF-IDF\n",
    "    try:\n",
    "        print(f\"We process now {company}\")\n",
    "\n",
    "        text_1, company_name, path, source = pdf_loader(company)\n",
    "        prep_text = preprocessing(text_1)\n",
    "        lemma_words = lemmatize_words(prep_text)\n",
    "        text_cleaned = remove_small_tokens(lemma_words)\n",
    "        top_n_words = get_top_n_words(text_cleaned, 20)\n",
    "        top_n_words = list(top_n_words.itertuples(index=False, name=None))\n",
    "        top_n_words\n",
    "        tf_idf = get_tf_idf(text_cleaned, 20)\n",
    "        tf_idf = tf_idf.reset_index()\n",
    "        tf_idf = tf_idf.rename(columns={\"index\": \"Word\"})\n",
    "        idf_list = list(tf_idf.itertuples(index=False, name=None))\n",
    "        idf_list\n",
    "        data = [(company_name, idf_list, top_n_words)]\n",
    "        df1 = pd.DataFrame(data, columns = [\"Company Name\", \"TF-IDF\", \"Top N Words\"])\n",
    "        company_name_new = f\"{df1['Top N Words'][0][0][0]}_{df1['Top N Words'][0][1][0]}_{df1['Top N Words'][0][2][0]}\"\n",
    "\n",
    "        ## Full Text Topic Modeling\n",
    "\n",
    "        text = pdf_loader(company)\n",
    "        text = preprocessing_text(text)\n",
    "        result_df = topic_modeler(text)\n",
    "        result_df.to_csv(\n",
    "            fr\"..\\Data\\Resultate\\Testfolder\\Zero Shot Learning Fulltext\\{company_name_new}_FullText_TopicModeling.csv\")\n",
    "\n",
    "        print(f\"{company_name_new} SAFED\")\n",
    "    except:\n",
    "        print(f\"{company} didn't work\" )\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcf02d00a6b3e7f0f947d643ae902f18bdd390f284f55fc20de5769d141d0127"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
